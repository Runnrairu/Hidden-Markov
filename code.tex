\documentclass[dvipdfmx, a4paper]{jsarticle}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{type1cm}
\usepackage{bm}
\usepackage{amsthm}
\newtheorem{theo}{定理}[section]
\newtheorem{defi}{定義}[section]
\DeclareMathOperator*{\argmin}{argmin}


\title{数学科向け機械学習入門（体験版）}
\author{}

\begin{document}
\maketitle

\section{はじめに}
世は空前の人工知能ブーム。猫も杓子もAIだディープラーニングだと、なんでも機械学習に任せてしまえばいいという考えが蔓延している。

機械学習エンジニアの待遇の良さや需要の高さを耳にする機会は多いことだろう。かつて数学徒の目指す職種としてありがちだったクオンツやアクチュアリーと違い、スーツを着ることを強要されるのが少ないという点も魅力的だ。そうなると「自分も機械学習を学んでAIエンジニアになり、ガッポガッポ大儲け。タワーマンションの上層階でたくさん女侍らして、高級ワインを飲むんじゃあ！」という思考になり、機械学習の本に手が伸びる数学徒も少なくないことかと思う。

しかし、勉強をし始めた多くの数学徒は匙を投げてしまう。その理由の大半が「あまりに数学的に適当すぎて読んでいられない」というものだ。

その気持ちはよくわかる。かく言う私もそうだった。世間には「一般向け」と称した、あまりにも粗雑な機械学習の入門書が溢れかえっており、数学的にまともな文献は少数派だ。もちろん一部存在はするが、とてもじゃないが初学者が読んで役立てることはあまりに難しい。

数学的に適当、とは具体的にどういうことなのか。これは大きく分けて３つあるように思う。

\begin{enumerate}
\item 確率測度と確率密度関数が区別されていない
\item 確率変数であるものと確率変数でないものが区別されていない
\item 目の前の関数がどこからどこへの写像かわからない
\end{enumerate}

ある程度わかってくるとなんとなく忖度して雰囲気で読んでいくことができるようになるが、厳密に読んでいく訓練を受けてきた機械学習初学者の数学徒にはなかなか酷な話だ。

そのため、本書の前半ではなるべく数学科の解析学の授業で習う用語、流儀を用いて、機械学習の基礎を書くことを心掛けた。本書の内容を理解すれば、そう苦労せず一般向けの機械学習資料を読んでいくことができるはずだ。

　

前半部分の前提知識は数学科学部レベルの関数解析学、確率論、数理統計学とする。後半はその限りではない。

体験版追記：本書は体験版ということで、ページ数も限られるのもあり、具体的な手法についてあまり詳細な解説はできていない。特にベイズを用いた推定の具体的なやり方についてはほとんど解説できなかったと言っていい。興味のある人は自力で調べてみてほしい。本書を読みこなせた人なら難なく学べるはずだ。

\newpage
\section{機械学習入門}

\subsection{問題設定}
\subsubsection{大枠設定}
まずおおもとの完備な確率空間$(\Omega,\mathcal{F},P)$を設定する。

特に表記がなければ、すべての可測空間のσ加法族はボレル集合族、線形空間に対応する体は実数体であるものとする。

線形距離空間$\mathcal{X}$を特徴量空間、線形距離空間$\mathcal{Y}$をラベル空間と呼び、それぞれの元$x,y$を「特徴量」「ラベル」と呼ぶ。

ここで、データから何らかの「よい」写像$f:\mathcal{X}\to\mathcal{Y}$を構成するのが「機械学習」である。機械学習とは、関数近似の機構なのである。

ここで、独立同分布な確率変数列$\mathcal{D}\coloneqq\{D_i(\omega)\}_{i=1}^n$を考える。各$D_i$は$D_i\colon\Omega\to\mathcal{X}\times\mathcal{Y}$となる可測関数である。この確率変数列$\mathcal{D}(=\{D_i\}_{i=1}^n)$を入力データと呼び、確率変数$D_i$の$\mathcal{X},\mathcal{Y}$への射影をそれぞれ$X_i,Y_i$と表記する。

増大情報系$\mathcal{F}_0\subset\mathcal{F}_1(\subset\mathcal{F})$を考える。$\mathcal{F}_0$はデータ観測前の保持情報、$\mathcal{F}_1$はデータ観測後の保持情報である。すなわち
\begin{align}
\mathcal{F}_1\coloneqq\mathcal{F}_0\vee\sigma([D_i]^n_{i=1})
\end{align}


連続写像$f\colon\mathcal{X}\to\mathcal{Y}$の満たす集合全体を$\mathcal{Z}$と表記する。モデルに対応した$\mathcal{Z}$の部分集合(詳細は後述)を$\mathcal{Z}_M$と書く。

連続汎関数$F\colon\mathcal{Z}\rightarrow\mathbb{R}$の集合を$\mathcal{Z}^*$と書く。$\mathcal{Z}^*$の位相は弱位相であるとし、$\mathcal{F}_1$-可測な確率変数$F^*\colon\Omega\rightarrow \mathcal{Z}^*$によって定義される評価関数$F_\mathcal{D}\coloneqq F^*(\omega)$に対して
\begin{align}
\hat{f}\coloneqq argmin_{f\in \mathcal{Z}_M}F_\mathcal{D}(f)
\end{align}

を満たす$\hat{f}\in \mathcal{Z}_M$を見つける。これが機械学習における大枠の問題設定である。

\subsubsection{パラメータを通した$\hat{f}$の構成方法}
パラメータを導入する。パラメータの集合となる２つの線形位相空間を$\Theta_0,\Theta$と表記する。写像$\theta^*:\Theta\to\mathcal{Z}$はあらかじめ一つ固定しておき、確率変数$\hat{\theta}_0(\omega)\colon\Omega\to\Theta_0,\hat{\theta}(\omega)\colon\Omega\to\Theta_1$を考える。実際に機械学習問題を解くにあたっては、この$\hat{\theta}$を構成することを通して関数$\hat{f}$を構成する。今後は、分かりやすくするために$\theta^*(\theta)$を$f(\cdot,\theta)$と表記する。

今後本書では、$\theta_0$をハイパーパラメータ、$\theta$をパラメータと呼び、単にパラメータといった場合は後者のみを指すものとする。ハイパーパラメータはパラメータの数や後述の事前分布の分散など、パラメータにまつわる数値を決定するものである。

(ここで、聡明な読者は「$\mathcal{Z}_M=Im(\theta^*)$でいいのでは？」と思うかもしれない。しかし、これではベイズ的な機械学習おいて非常に困る事態が起こってしまう。$Im(\theta^*)\subset\mathcal{Z}_M$は常に成り立つが、逆は頻度論でしか成り立たない)

$\hat{\theta}$の$\mathcal{F}_0$-条件付き確率、$\mathcal{F}_1$-条件付き確率をそれぞれ事前確率、事後確率と呼ぶ。またそれらの確率測度に$\Theta$上のルベーグ測度とのラドンニコディム導関数が存在すれば$p(\theta),p(\theta|\mathcal{D})$と書き、事前分布、事後分布と呼ぶ。

\subsubsection{問題設定}
ここでいよいよ統一的な問題設定を定義する。

特徴量空間$\mathcal{X}$、ラベル空間$\mathcal{Y}$、データ$\mathcal{D}$、評価関数$F_\mathcal{D}$、事前分布$p(\theta)$、事後分布$p(\theta|\mathcal{D})$、超事前分布$p(\theta_0)
$、パラメータ$\hat{\theta}$の可測性、パラメータと$f$の関係$\theta^*(\theta)$をまとめて$(\mathcal{X},\mathcal{Y},\mathcal{D},F_\mathcal{D},p(\theta),p(\theta|\mathcal{D}),p(\theta_0),\hat{\theta}-mesurable,\theta^*(\theta))$と表記し、これを今後「機械学習問題」と呼ぶことにする。

これができるだけ「よい」関数になるよう調整したい。このとき$\hat{f}$が実現できる範囲の集合こそが$\mathcal{Z}_M$であり、一般には「仮説集合」と呼ばれる。(ちなみに、$\hat{\theta}_0,\hat{\theta}$が共に$\mathcal{F}_1$-可測であれば、これは$Im(\theta^*)$と一致する)

また、$\hat{\theta}_0$が$\mathcal{F}_0$-可測で$\hat{\theta}$が$\mathcal{F}_1$-可測である場合を頻度論的機械学習問題と呼び、$\hat{\theta}_0$が$\mathcal{F}_0$-可測だが$\hat{\theta}$が$\mathcal{F}_1$-可測でない場合をベイズ論的機械学習問題と呼ぶ。ベイズ論の解説は次章にて。

また、$\hat{\theta}_0,\hat{\theta}$が共に$\mathcal{F}_1$-可測でない場合を階層ベイズ論的機械学習問題と呼ぶが、本書では扱わない。つまり$\hat{\theta_0}$はすべてデータ観測前の段階であらかじめ決まっている定数であるものとする。


\subsection{代表的なモデル}
いよいよここから機械学習における代表的なモデルについて説明する。ここまでの問題設定が難解だった分、ここからはかなりあっさり進んでいくことができる。

解説するモデルは大きく分けて3つ、「線形回帰」「カーネル回帰」「ニューラルネットワーク」である。カーネル回帰とニューラルネットワークは後の章で詳細な数学的研究について解説するため、この章では触りだけで済ませる。

このいずれに対してもある関数を決め、最終的に構成される関数はそれとパラメータの積の和とするのが普通である。

\begin{align}
線形回帰（基底関数）　\{\phi_i:\mathcal{X}\to\mathcal{Y}\}^n_{i=1}(Nはハイパーパラメータとして定める)\\
カーネル回帰（カーネル関数）　k:\mathcal{X}^2\to\mathcal{Y}\\
ニューラルネットワーク（活性化関数）　\eta:\mathbb{R}\to\mathbb{C}
\end{align}

\subsubsection{線形回帰}
最も基本的なモデルである。

写像$\theta^*:\Theta\to\mathcal{Z}$は次のように定義する。
\begin{align}
\theta^*(\theta)(x)\coloneqq \Sigma^d_{j=1}\Sigma^N_{k=1} \theta_{kj}\phi_k(x_j)
\end{align}

ただし、$\theta_{kj}$は、行列$\theta\in\mathbb{R}^{N\times d}$の$kj$成分である。

そして、入力データ$\mathcal{D}$に対して、評価関数$F_\mathcal{D}\colon \mathcal{Z}\to\mathbb{R}$は次のように定義する。
\begin{align}
F_\mathcal{D}(f)\coloneqq \frac{1}{2}\Sigma^n_{i=1}||Y_i-f(X_i)||_\mathcal{Y}^2
\end{align}

これを最小化するような行列$\theta\in\mathbb{R}^{N\times d}$を求めればよい。ただし、$||\cdot||_\mathcal{Y}$は$\mathcal{Y}$上の距離である。


ところで、聡明な読者はこう疑問に思ったかもしれない。「Nを際限なく大きくとれば、どんなデータに対しても完璧に近似できるのでは？」と

その予測は正しい。確かに$n<N$であれば、基底関数がよほど歪でない限り損失関数はかならず０にできてしまう。しかし、そのようにして作った関数が、未知のデータに対して力を発揮できるだろうか（未知のデータへの予測性能を汎化性能という）

もちろんそんなことはない。強引な近似を行えば、データのノイズにもフィッティングしてしまい、とてもじゃないが未知のデータに対する予測性能などもてるはずもない（これを過学習という）

かといって、表現能力の低い近似だとろくな予測性能を発揮できない（これを未学習という）

未学習を無理に解決すると過学習を起こし、過学習を無理に解決すると未学習を起こす。（これを、バイアスとバリアンスのトレードオフという）

では、その過学習と未学習の折り合いをつけるにはどうすればよいか。その代表例が「正則化」と呼ばれる手法である。正則化は、簡単に言うと「近似の複雑さにペナルティを与える」手法だ。基本的には次のように定義する。

\begin{align}
F_\mathcal{D}(f)\coloneqq \frac{1}{2}\Sigma^n_{i=1}||Y_i-f(X_i)||_\mathcal{Y}^2+\lambda\Sigma_k\Sigma_j|\theta_{kj}|^l
\end{align}

ただし、$l$は自然数1もしくは2で、$l=1$のときこれを「Lasso回帰」,$l=2$のときこれを「Ridge回帰」という。$\lambda$は$\theta_0$の実数部分となるハイパーパラメータで、0.01や0.001くらいの数字がセットされる場合が多い。

Lasso回帰にはパラメータが疎になりやすい（値が０になるパラメータがたくさん存在する可能性が高い）、またRidge回帰は数学的な扱いが楽で解析的に最適化できる、という特徴があり、どちらも一長一短である。

機械学習問題としては、$(\mathbb{R}^d,\mathbb{C},\mathcal{D},\frac{1}{2}\Sigma^n_{i=1}||Y_i-f(X_i)||_\mathcal{Y}^2+\lambda\Sigma_k\Sigma_j|\theta_{kj}|^l,-,-,(N,\lambda),\mathcal{F}_1-mesurable,\Sigma^d_{j=1}\Sigma^N_{k=1} \theta_{kj}\phi_k(x_j))$


\subsubsection{カーネル回帰}
一昔前に流行ったサポートベクターマシンなどにつながっていく方法である。

カーネル関数$k:\mathcal{X}^2\to\mathcal{Y}$を決めておく。ハイパーパラメータは正則化項の係数$\lambda$のみ。パラメータは$\theta:=\{a_i\}^n_{i=1},\Theta:=\mathbb{R}^n$という形で定める。

データ数をこれまでと同じく$n$とおいて

\begin{align}
f(x):=\Sigma_{i=1}^na_ik(x,X_i)
\end{align}

という形であらわされる関数に対してパラメータを決定する。

カーネル回帰でも正則化は同様に行う。すなわち評価関数は

\begin{align}
F_\mathcal{D}(f):=\Sigma_{i=1}^n||Y_i-f(X_i)||_\mathcal{Y}+\Sigma_{i=1}^n||a_i||^l
\end{align}

kの満たしている条件などの詳細は4章にて。

\subsubsection{ニューラルネットワーク}
最近流行りの手法である。ここではシャロウニューラルネットについて解説する。

ハイパーパラメータは中間層ノード数、ステップ数、学習率の３つである。これらをそれぞれ$N\in\mathbb{N},Step\in\mathbb{N},\epsilon\in\mathbb{R}$と表記する。すなわち$\Theta_0:=\mathbb{N}^2\times\mathbb{R}$

パラメータに関しては、$a\in\mathbb{R}^d,b\in\mathbb{R},C\in\mathbb{C}$と表記する。今後a,bの存在する空間$\mathbb{R}^{d+1}$のことを$\mathbb{Y}^{d+1}$と書く。このa,b,Cの組を$N$と同数用意するため、$\Theta:=(\mathbb{Y}^{d+1}\times\mathbb{C})^N$となる。

\begin{align}
f(x):=\Sigma_{j=1}^NC_j\eta(a_j\cdot x-b_j)
\end{align}

ただし、$a_j\cdot x$はユークリッド内積を表す。

損失関数はいつもと同じで

\begin{align}
F_\mathcal{D}(f):=\frac{1}{2}\Sigma^n_{i=1}||f(X_i)-Y_i||^2_\mathcal{Y}
\end{align}

機械学習問題としては$(\mathbb{R}^d,\mathbb{C},\mathcal{D},\frac{1}{2}\Sigma^n_{i=1}||Y_i-f(X_i)||_\mathcal{Y}^2,-,-,(N,Step,\alpha),\mathcal{F}_1-mesurable,F_\mathcal{D}(f):=\Sigma^n_{i=1}||f(X_i)-Y_i||_\mathcal{Y}$

このニューラルネットワーク、学習結果を解析的に計算するのはまず不可能である。（実はノード数が無限大なら解析的に計算する方法がある。その理論と、それを用いた手法については5章で解説する）そのため、実際にはパラメータによって生まれる勾配からパラメータを更新していく。

すなわち、mステップ目のあるパラメータ$\theta^m_j$を$\theta^{m+1}_j$に更新する式は

\begin{align}
\theta^{m+1}_j:=\theta^m_j-\epsilon\nabla_{\theta_j}\frac{\partial F_\mathcal{D}(f)}{\partial \theta_j}|_{\theta^m_j}
\end{align}

すなわち、損失関数を$\theta$の関数ととらえて、各$\theta_j$ごとに傾きの方向大きさに応じてそちら方面に摺り寄せる。これをStep回繰り返す。

ニューラルネットはこの３つの手法の中でもっとも表現能力が高く、過学習もしやすいし、極値にもハマりやすい。正則化もパラメータが明らかに等価に扱えるものではないため、そのままノルムを計算してもうまくいかない。

過学習や極値にハマるリスクを抑える方法はドロップアウトや確率的勾配法などいろいろとあるが、本書では解説しない。

\newpage
\section{ベイズ学習}
この章では、ベイズ論的機械学習についてもう少し掘り下げる。ベイズを用いるため、$\hat{\theta}_0$は$\mathcal{F}_1$-可測だが、$\hat{\theta}$は$\mathcal{F}_1$-可測ではない。ベイズ論に深入りすると一生機械学習の議論に戻ってこれなくなるため、簡単に入口だけを解説する。


\subsection{ベイズの定理と共役事前分布}
ベイズの手法を用いる時も、普通に前章と同じく$\theta^*(\theta):=f$を決めておく。ただし、問題は$\theta$が時刻１で可測になっていない点にある。そのため

\begin{align}
\hat{f}(x)=\int_\Theta f(x,\theta)p(\theta|\mathcal{D})d\theta
\end{align}

とする（要するに$\mathcal{F}_1$条件付き期待値）。果たしてこんなものを解析的に計算するなどということが、本当にできるのだろうか。

もちろん一般には現実的なリソースで計算できるものではない。実際にこれを近似計算する方法のうち代表的なものは２つあり、
\begin{enumerate}
\item MCMCを利用する
\item 共役事前分布を利用する
\item 変分推論
\end{enumerate}

2.2項ではこの1.2の手法について解説する。

\begin{theo}ベイズの定理

$\hat{\theta}=\theta$である時のデータ$D_i$の尤度を$p(D_i|\theta)$と表記する。

このとき、任意の$\theta\in\Theta$に対して、ある定数$W$が存在し、次の式が成り立つ
\begin{align}
p(\theta|\mathcal{D})=\frac{1}{W}p(\theta)\Pi^n_{i=1}p(D_i|\theta)
\end{align}
\end{theo}
この$W$を解析的に表現するのは簡単だが、実際にパソコン上で求めるとなると非常に難しい。ここでの2つの手法は、どちらもこの定数を計算せずに済む方法である。
\subsubsection{マルコフ連鎖モンテカルロ法}
まず、基本的な考え方として「比がわかればその具体的な値を知る必要はない」というものがある。

例えば、箱の中にたくさんの青いボールと赤いボールが入っており、赤いボールを引けば100万円もらえるが、青いボールを引くとなにももらえないという状況があったとする。
このとき、引く人間の関心ごとは「赤いボールと青いボールの個数の比は」であって、それさえわかれば「赤いボールと青いボールがそれぞれ何個入っているか」は気にならないはずだ。そして、ボールを一個引き出したときにもらえる金額の期待値を求めたいときにはどうすればいいか。最も手っ取り早いのは、「適当に大量のボールを取り出して、その中の赤と青の比を見る」ことであろう。

このモンテカルロ法はそういった発想に基づいている。サンプリングされる$\theta$の確率分布が$p(\theta|\mathcal{D})$に近くなるような方法で、多数の$\theta$をサンプリングしてくるのである。

$\{\theta_1,\theta_2,......,\theta_N\}$と$N$個の$\theta$を事後分布に従うようサンプリングしてきたとする。そうしたら、平均値$\frac{1}{N}\Sigma^N_{i=1}f(x,\theta_i)$は、$N\to\infty$により$\int_\Theta f(x,\theta)p(\theta|\mathcal{D})d\theta$に$\mathcal{X}$上ほとんど至るところ確率１で収束する。

事後分布からの具体的なサンプリング方法については、今回は説明しない。


\subsubsection{共役事前分布}
実は、事前分布と尤度関数の間にある関係を仮定すれば、MCMCのような複雑な手法を使うよりも圧倒的に簡単な方法で事後分布を直接計算できる。実際には分析対象がよほどアレなデータでない限り、こちらの方法を用いることが多い。

事前分布と尤度関数が「ガンマ分布-ポアソン分布」など、特定の組み合わせに該当すれば、事後分布は事前分布のパラメータを変更したものになる。

\subsection{誤差の見積もり}

ベイズの特徴としては、「判断誤差を見積もれる」という点がある。

関数$f(x)$の代わりに$\mathcal{X}\times\mathcal{Y}$上の密度関数$p:\mathcal{X}\times\mathcal{Y}\to\mathbb{R}_+$を推定したい。上記の計算と同じように

\begin{align}
\hat{p}(y|x)=\int_\Theta p(y|x,\theta)p(\theta|\mathcal{D})d\theta
\end{align}

という計算で$x$に対する周辺分布が計算できる。ただし、$p(y|x)$は$D=(X,Y)$に対して$X=x$が成り立つときの条件付き密度。$p(y|x,\theta)$も同様に定義される。

\subsection{変分推論}

変分推論とは、$\Theta$上のわかりやすい密度関数$q(\theta)$を、なるべく$p(\theta|\mathcal{D})$に似せよう、という手法である。実現可能な$q$の集合を$\mathcal{Q}$とおき。
\begin{align}
\hat{q}:=argmin_{a\in\mathcal{Q}}KL(q||p)
\end{align}

によって$q$を求める。

$KL(q||p)$は、カルバックライブラー情報量と呼ばれる基準で、$p$と$q$の間の、ある種の「距離」を表す。

　

ベイズの測度論を用いた厳密な定式化は、主に渡辺澄夫氏によって研究されている。渡辺氏の理論では平気な顔して代数幾何が登場するので、興味がある人はぜひ調べてみよう。ここではそのような領域にまでは立ち入らない。情報量基準による議論を微分幾何学でゴリ押しする情報幾何学もおすすめだ。

\newpage
\section{再生核ヒルベルト空間とカーネル法}
この章では、前章で簡単にしか触れられなかったカーネル法の、もっと詳細な理論的背景の入り口を解説する。
\subsection{再生核ヒルベルト空間}
\begin{defi}カーネル関数

写像$k:\mathcal{X}^2\to\mathcal{Y}$が対称非負定値関数であるとは、任意の$x_1,x_2,......,x_n\in \mathcal{X}$に対して
\begin{align}
k(x_i,x_j)=k(x_j,x_i)\\
任意のc_1,c_2,......,c_n\in\mathbb{R}に対して、\Sigma^n_{i=1}\Sigma^n_{j=1}c_ic_jk(x_i,x_j)\geq0
\end{align}

が成り立つことである。この時、$k$を$\mathcal{X}$上のカーネル関数であるという。
\end{defi}
\begin{defi}再生核ヒルベルト空間

写像$\mathcal{X}\to\mathcal{Y}$全体の部分集合でヒルベルト空間となるもの$\mathcal{H}$が、再生核$k$を持つ再生核ヒルベルト空間であるとは、次が満たされることを言う。
\begin{align}
任意のx\in\mathcal{X}に対して、k(\cdot,x)\in\mathcal{H}\\
任意のx\in\mathcal{X},f\in\mathcal{H}に対して、<f,k(\cdot,x)>_\mathcal{H}=f(x)
\end{align}

厳密にいえば、対称非負定置関数に対して、それを核とする再生核ヒルベルト空間が一意に存在する。
\end{defi}

\subsection{カーネル表現定理}
上記の設定を踏襲したうえで、$f\in\mathcal{H},b\in\mathcal{Y}$と置く。前々章の問題設定でいうと$\mathcal{Z}_M=\mathcal{H}+\mathcal{Y}$と書ける。ここで損失関数は一般には次のように表記できる。
\begin{align}
F_\mathcal{D}(f+b):=L(f+b;\mathcal{D})+\Psi(||f||_\mathcal{H})
\end{align}

ただし、$L:\mathcal{Z}_M\to\mathbb{R},\Psi:\mathbb{R}\to\mathbb{R}$であり、$\Psi$は単調非減少関数である。このとき、次の定理が成り立つ。
\begin{theo}カーネル表現定理

$f+b\in\mathcal{Z}_M$とする。このとき、$F_\mathcal{D}$を最小化するような$\hat{f}\in\mathcal{H},\hat{b}\in\mathcal{Y}$が存在すれば、そのような$f\in\mathcal{H}$の中に
\begin{align}
f(x)=\Sigma^n_{i=1}\hat{a}_ik(x,X_i)
\end{align}

と表記できるものが存在する。

ただし、$\{\hat{a}_i\}^n_{i=1}\in\Theta$である。
\end{theo}



\newpage
\section{ニューラルネットワークの積分表現理論}
この章では、「中間層のノード数が無限大であれば学習結果を解析的に決定できる」という理論に基づく、ニューラルネットのアルゴリズムについて簡単に解説する。

中間層のノード数が無限大だった場合、ニューラルネットの計算はある関数$T(a,b)$を用いて次のように書ける。
\begin{align}
f(x)=\int_{\mathbb{Y}^{d+1}}T(a,b)\eta(a\cdot x-b)dadb 
\end{align}

近似したい関数$f:\mathbb{R}^d\to\mathbb{C}$に対して、リッジレット関数$\psi$と活性化関数$\eta$が適当な条件を満たす場合、リッジレット作用素と呼ばれる線形作用素$\mathcal{R}_\psi$を用いて
\begin{align}
f(x)=\int_{\mathbb{Y}^{d+1}}(\mathcal{R}_\psi f)(a,b)\eta(a\cdot x-b)dadb
\end{align}

が$\mathcal{X}$上ほとんどいたるところで成り立つ。つまりこのリッジレット作用素によって、学習結果であるはずの$T(a,b)$を解析的に計算できてしまう。

もちろん実際には有限のノードしか使えないので近似が必要だが、この理論を用いて初期値を決定すると、精度、速度ともに向上がみられる。

\subsection{活性化関数が有界な場合}
まずは$\eta\in L^\infty(\mathbb{R}\to\mathbb{C})$が成り立つ場合について解説する。

\begin{defi}リッジレット変換

$f\in L^1(\mathbb{R}^d\to\mathbb{C})$のリッジレット関数$\psi\in L^\infty(\mathbb{R}\rightarrow\mathbb{C})$によるリッジレット変換は、次のように定義される。
\begin{align}
(\mathcal{R}_\psi f)(a,b):=\int_{\mathbb{R}^{d}}f(\bm{x})\overline{\psi(a\cdot\bm{x}-b)}|a|^sd\bm{x}
\end{align}
ただし、$s$は非負実数。0か1を使うことが多い。
\end{defi}

このリッジレット作用素の双対作用素はこのようになる。

\begin{defi}双対リッジレット変換
関数$T\in L^1(\mathbb{{Y}^{d+1}}\rightarrow\mathbb{C};|a|^{-s}dadb)$の、活性化関数$\eta\in L^\infty(\mathbb{R}\rightarrow\mathbb{C})$による双対リッジレット変換は
\begin{align}
(\mathcal{R}^*_\psi T)(x):=\int_\mathbb{Y}^{d+1}T(a,b)\eta(a\cdot x-b)|a|^{-s}dadb
\end{align}
となる。
\end{defi}

このリッジレット関数と活性化関数に対して、次の許容条件を定義する。

\begin{defi}許容条件
関数$f$に対して、$\hat{f}$で$f$のフーリエ変換を表すとする。

次の積分$K_{\eta,\psi}$が収束し、かつ０でないとき、この活性化関数とリッジレット関数の組$(\eta,\psi)$は許容的であるという。
\begin{align}
K_{\eta,\psi}:=(2\pi)^{d-1}\int_\mathbb{R}\frac{\overline{\hat{\psi}(\xi)}\hat{\eta}(\xi)}{|\xi|^d}d\xi
\end{align}
\end{defi}

そして、次の式がニューラルネットによる近似可能性の一つの答えを出す定理である。

\begin{theo}再構成公式
$f,\hat{f}\in L^1(\mathbb{R}^d\rightarrow\mathbb{C})$で、$(\eta,\psi)$は許容的な組み合わせであるとする。
\begin{align}
\mathcal{R}^*_\eta\mathcal{R}_\psi f(x)=K_{\eta,\psi}f(x)
\end{align}

が、$\mathcal{X}$上a.eで成り立つ。
\end{theo}

\subsection{活性化関数が有界でない場合}
機械学習に取り組んだことのある方は疑問に思ったことだろう。「じゃあ$\eta$がReluやSwishのような、どう見ても$L^\infty$じゃない場合はどうするのか」と。

実際既存の積分表現理論は、活性化関数の有界性に甘えていた。しかし、Reluが有用である理由の一つに「勾配が消失しない」というものがあり、これは非有界性と切り離すことができない。2015年に出た論文である[10]によって、ようやく非有界な活性化関数の一部に対しても積分表現理論を行えるようになった。（[10]を読めば、非有界な活性化関数を持つニューラルネットを数学的に扱うことがいかに大変で、論文著者が苦労したかよくわかる）

活性化関数のクラスを拡張した代償は、リッジレット関数の範囲である。活性化関数を$L^\infty$から$\mathcal{S}^`$に広げた代わりに、リッジレット関数がとれる範囲は$L^\infty$から$\mathcal{S}$まで縮小している。

それに加え、一定の条件を満たせばリッジレット変換は$L^2$に一意的に拡張でき、$L^2$関数に対する再構成公式も定義できる。

この関数解析的な議論を活かしたアルゴリズムについては[5]を参照。


\newpage
\section{数学×機械学習}
この章では、ある程度機械学習の経験があり、数学知識も豊富な人向けに、機械学習の数値計算への応用や、逆に数値計算の技法を機械学習に応用する方法について解説する。

\subsection{ニューラルネットワークの数値解析への応用}
ここでは、PDEs（放物型偏微分方程式）の境界値問題への数値計算に応用する手法について解説する。

PDEの数値解析理論は、現状空間が4次元以上だと誤差がひどいことになってしまう。株式の銘柄の数だけ次元が増えるファイナンスなど、SDEやPDEの応用分野ではこれが大いに問題になることも多い。
 
今回扱う半線形放物型PDEの境界値問題は次のような形をしている。
\begin{align}
\frac{\partial u}{\partial t}(t,x)+\frac{1}{2}(\Delta_xu)(t,x)+f(u(t,x),(\nabla_xu)(t,x))=0\\
u(T,x)=g(x)
\end{align}


ただし、$x$の取りうる空間は$\mathbb{R}^d$,$f:\mathbb{R}\times\mathbb{R}^d\rightarrow \mathbb{R},g:\mathbb{R}^d\rightarrow\mathbb{R}$は既知の連続関数であるとし、$u:[0,T]\times\mathbb{R}^d\rightarrow \mathbb{R}$は$C^{1,2}$級とする。

\begin{theo}非線形ファインマンカッツの公式

$W$を$d$次元標準ブラウン運動。確率空間をそこから生成されるものとし、$Y,Z$は適合過程で、$f,g$は先ほどと同じで、$\xi\in\mathbb{R}^d$とする。

\begin{align}
Y_t=g(t,\xi+W_T)+\int^T_tf(Y_s,Z_s)ds-\int^T_t<Z_t,dW_t>
\end{align}

は、上記の半線形熱方程式終端値問題の解$u$に対して次を満たす

\begin{align}
Y_t=u(t,X_t),Z_t=\nabla_xu(t,X_t)
\end{align}
ただし、$X_t:=\xi+W_t$
\end{theo}

このブラウン運動は、学習の反復1回ごとにオイラー丸山法で実装する。
今回、このニューラルネットワークを用いた強化学習で学習させる対象は、写像$Z_t=F_t(X_t)$。
通常の強化学習での評価関数にあたるものは$Y_t=Q(t,Z_t)$と定義される。

そしてこの評価関数は、終端時刻$T$にて、
\begin{align}
\psi(\theta)=||Y_T-g(X_T)||^2
\end{align}
で評価され、通常の強化学習と同じく更新されていく。

つまり、時刻がN分割の場合、「毎回N回の行動をとった後に一度だけ報酬が与えられる状況での強化学習」と見なして、$X_t$に対する最適戦略$Z_t$と$Y_t$を導き出して、それを偏微分方程式の数値解析結果にするという考えである。

通常のQ-学習と違い、状態$X_{t_n}$と方策$Z_{t_n}$と前時刻での評価$Y_{t_{n-1}}$から一意的にこの式で$Y_{t_n}$が定まるため、その意味では楽だといえる。

\begin{align}
Y_{t_{n+1}}\approx Y_{t_n}-f(Y_{t_n},(\nabla_xu)(t_n,\xi+W_{t_n}))(t_{n-2}-t_{n-1})+<(\nabla_xu)(t_n,\xi+W_{t_n}),W_{t_2}-W_{t_1}>
\end{align}
ニューラルネットは各時刻で用意する。つまりこれはRNNではなく、単純に$N$個のニューラルネットが存在するのみである。時刻が違う中間層同士のつながりはない。

損失関数$\psi(\theta)$で計算された結果から、新たなパラメータを決定する。すなわち、学習$m$回目のパラメータを$\Theta_m$とおくと
\begin{align}
\Theta_{m+1}:=\Theta_{m}-\nabla_\theta\psi(\Theta_m)
\end{align}

これは要するに確率的勾配法による学習で、ニューラルネットワークに偏微分方程式の正しい関数を近似させようとする取り組みだ。

ただし、普通の確率的勾配法はデータの集合$\mathcal{D}$上の一様測度の元で行われていたが、今回は$C([0,T])$上のWiener測度の下で確率的勾配法を行っているのである。

「ならばAdam法などをこの手法に適用してはどうか」「ということは確率過程になるので、抽象Wiener空間上の解析を離散化したものと捉えて収束証明ができるのではないか」「カメロン-マルティン部分空間が絡んでくるのではないか」という当然の疑問が浮かんでくる読者もいるだろうが、それは今後の課題である。

\subsection{数値解析の深層学習への応用}

\subsubsection{深層学習とは}
これまでの章で扱ったニューラルネットワークは、入力層と隠れ層と出力層が１つずつであったが、ここからは隠れ層が２つ以上のもの、つまり$N$層パーセプトロン$(N>3)$を扱っていく。

近年、結果をあげている深層学習アルゴリズムの層数は圧倒的に深くなっている。数年前は結果を出しているのはせいぜい８層、22層程度だったが、2015年に某大会で152層のニューラルネットワークが成果を上げたのを皮切りに、現在では1000層を超えるネットワークも使われている。

\subsubsection{残差学習とは}
なぜそのような超深層学習が可能になったのか、そのカギを握るのは。残差学習という概念だ。

これまでの章を読んでもらえばわかる通り、通常のニューラルネットワークは入力$x$に対して、学習させたい写像$H(x)$を直接学習させる。

しかしこの手法は3～6層程度のパーセプトロンなら有効だが、層の数が劇的に増えてくると意味をなさなくなってくる（勾配消失・発散）。それを突破するためにいろいろな方法が考えられたが、どれも中間層の数が数百、数千層単位になる超深層学習には対応できなかった。

そこで登場するのが残差学習である。学習させる対象は、$H(x)$ではなく、残差$F(x):=H(x)-x$、これを学習させ、そこに$x$を加えた値を次の層の入力とする。

ここで、この残差関数$F$の、$n$番目の層での値を$F(t_n,\cdot)$と表記する。また、$n$番目の層の入力を$x_{t_n}$と表記する。

すると、この残差学習はこう書ける。
\begin{align}
x_{t_{n+1}}=x_{t_n}+F(t_n,x_{t_n})
\end{align}

これまで数学を学んできた読者ならすでにお気づきだろう。これは常微分方程式のオイラー近似に他ならない。

すなわち、残差学習による超深層ニューラルネットで行われていることは、常微分方程式の離散近似なのである。

近年の主な超深層学習と常微分方程式数値計算の関係を簡単にまとめると
\begin{align}
ResNet &-& 前進オイラー法\\
RevNet &-& 後退オイラー法\\
PolyNet &-& 前進オイラー法（連立常微分方程式）\\
FractalNet &-& 2次ルンゲクッタ法
\end{align}　
さらに[5]の著者は、別の常微分方程式の数値計算技法を使うことで、さらなる計算の高速化及び精度の向上を可能にした。

\subsubsection{確率的超深層学習と確率微分方程式}
ここまで書かれたのは、決定論的な超深層学習である。ここにノイズ付加やドロップアウトなどの確率要素を加えると、必然これらの議論は確率微分方程式の話に突入する。

shake-shake-model

しゃけしゃけモデルとは、その「シェイクシェイク」と2度も言うことからわかる通り、まさに計算結果をシェイクするモデルである。

$\gamma_n$を(0,1)上の一様分布に従う確率変数とする。これはブロックごとステップごとに新たに生成される乱数である。そして$n$ブロック目の入力を$X_n$と置くと

\begin{align}
X_{n+1}=X_n+\gamma_n f_1(X_n)+(1-\gamma_n)f_2(X_n) 
\end{align}

これは、確率微分方程式の離散近似と見做せ、[7]の著者は別のSDE数値解析技術を用いて精度の向上を行った。

\subsection{確率的勾配法と確率微分方程式}
最近、機械学習界隈（の極一部）で盛り上がっている考察である。

近年は、ミニバッチ学習のことを確率的勾配法と呼ぶことが多く、この場でもそれに倣う。

通常のバッチ学習において、勾配はこのように決定される。
\begin{align}
\frac{dC}{d\omega}:=\Sigma_{i=1}^n \frac{dC_i}{d\omega}
\end{align}

ただし、$C_i$は、データ$D_i$に対する損失である。

確率的勾配法においては、勾配はこう書ける。

\begin{align}
\frac{d\hat{C}}{d\omega}:=\frac{n}{B}\Sigma_{j=1}^B \frac{dC_{i_j}}{d\omega}
\end{align}

確率的勾配法における１ステップごとのパラメータ変化は

\begin{align}
\Delta\omega=\frac{\epsilon}{n}(\frac{dC}{d\omega}+(\frac{d\hat{C}}{d\omega}-\frac{dC}{d\omega}))
\end{align}

と書ける。ここで$\frac{dC}{d\omega}$は、$\mathcal{F}_t$-可測だが、$\alpha := (\frac{d\hat{C}}{d\omega}-\frac{dC}{d\omega})$はステップごとに独立な確率変数である。$E[\alpha]=0,E[\alpha^2]=n(\frac{n}{B}-1)F(\omega)$($F(\omega)$は$\omega$毎に定まる定数)であり、$\alpha$は$\mathcal{F}_{t+1}$-可測であるため、伊藤の表現定理より、ある確率１で$[t,t+1]$上$L^2$である適合過程$f(s)$が存在し
\begin{align}
\alpha = \int^{t+1}_t f(s)dB_s
\end{align}

と表記することができる。$\alpha$の分散と伊藤積分の等長性より、$f(s)=\sqrt{n(\frac{n}{B}-1)F(\omega)}$が成り立ち、それによって(45)式は
\begin{align}
d\omega=\frac{\epsilon}{n}\frac{dC}{d\omega}dt+\frac{\epsilon}{n}f(t)dB_t
\end{align}

という確率微分方程式の離散化だと見做すことができる。

だから何だと思うかもしれない。同感だ。実際、確率的勾配法を確率微分方程式と見做すことによる明確な御利益は現時点ではない。（[11]ではこれによって最適なミニバッチサイズがバッチサイズに比例することを導き出したと主張しているが、それは$\alpha$の平均分散を求めれば十分であり、わざわざSDEの議論に持ち込む意味はない。おそらく論文著者が確率微分方程式を使ってみたかっただけである）

応用数学には予言性が必要だ。つまり、「数学的なこんな概念で記述できた」だけでは意味はなく、その応用先の学問を発展させて初めて価値を持つ。カタストロフィー理論はそれができずに廃れた。

例えば、積分表現理論はそれによってアルゴリズムの改善につながり、またニューラルネットによる近似可能性を証明したから価値がある。カーネルトリックの研究も、それによってカーネル法がうまくいく理由を証明できたことによって存在価値が保証された。6-2で解説した残差学習を微分方程式の離散化と捉えた研究も、このことにより超深層学習の設計に対して新たな一石を投じたから意味があるのだ。

そのため、このSGDをSDEと捉える考え方にも、現時点ではほぼ価値がない。だが、この考察がなんの意味もない無駄なものだったかというと、私はそうは思わない。この先、確率解析学の言葉を用いた議論による発展で、新たなアルゴリズムが開発されたり、「経験的にうまくいっている」だけだったアルゴリズムに収束性の証明が成されたりするかもしれないのだ。

私はここからマリアヴァン解析の議論に持ち込み、渡辺-吉田理論を用いて漸近的な性質を示したりできるのではないか、などと考えているが、それは今後の課題である。


\newpage
\section{あとがき}
如何だっただろうか。正直、（原稿締め切りとページ数制限と就活の狭間で慌てふためいたせいで）まだまだ解説しきれていない部分はたくさんある。特に、解説できたのがマルチタスクでない回帰問題のみというのが痛い。これからも加筆修正してgithubに上げていくが、お前の遅い筆を待つ気はない！という方はぜひとも参考文献リストの書籍や、その他書籍やQiita記事などを読んでいってほしい。

ここまで読んでくれた方なら、一体機械学習とは何をやっているのか、機械学習の背後にはどれだけ数学的な議論が隠れているのか、その一端を知ることができているはずだ。

本書の内容を理解した方であれば、きっと一般向けの機械学習書籍を読んでいくこともできるようになっているかと思う。是非とも、機械学習の勉強を進め、積極的に実践経験を積んでいってほしい。この手の分野は自分で手を動かしてナンボだ。本書はそこに辿り着くまでの手助けをしているに過ぎない。

では、読者の数学徒諸君と、機械学習の議論ができる日を楽しみにしながら、いったん筆を置くことにする。本書は常に修正・加筆に取り組んでいるため、意見等があったら気軽にメッセージを送ってほしい。面白い機械学習の数学的研究の資料の紹介なども大歓迎だ。




\begin{thebibliography}{99}
  \bibitem{キー} 確率論(実教理工学全書),西尾真紀子(1978)
  \bibitem{キー} Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series),Kevin.P.Murphy (2012)
  \bibitem{キー} ルベーグ積分入門-使うための基礎と応用-,吉田伸生(2006)
  \bibitem{キー} 関数解析,黒田成俊(1980)
  \bibitem{キー} 深層ニューラルネットの積分表現理論,園田翔(2017)
  \bibitem{キー} Deep learning-based numerical methods forhigh-dimensional parabolic partial differential equationsand backward stochastic differential equations,Weinan E,Jiequn Han,Arnulf Jentzen(2017)
  \bibitem{キー} BEYOND FINITE LAYER NEURALNETWORKS:BRIDGING DEEP ARCHITECTURES AND NUMERICAL DIFFERENTIAL EQUATIONS,Yiping Lu,Aoxiao Zhong,Quanzheng Li(2017)
  \bibitem{キー} カーネル法の新展開ーその理論と応用ー,福水健次(2012)
  \bibitem{キー} 統計的学習理論,金森敬文(2015)
  \bibitem{キー} Neural Network with Unbounded Activation Functions is
Universal Approximator,Sho Sonoda,Noboru Murata1(2015)
  \bibitem{キー} A BAYESIAN PERSPECTIVE ON GENERALIZATION AND
STOCHASTIC GRADIENT DESCENT,Samuel.L.Smith,Quoc.V.L(2017)
  \bibitem{キー} Non-Convex Learning via Stochastic Gradient Langevin
Dynamics: A Nonasymptotic Analysis,Maxim Raginsky,Alexander Rakhlin,Matus Telgarsky(2017)
  \bibitem{キー} 数理統計学,吉田朋友(2006)
\end{thebibliography}





\end{document}
